{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HYPuQ5VRtVXp"
      },
      "source": [
        "# DS 542 - Spring 2026 - Discussion 4"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_PLCzsV8YwoN"
      },
      "source": [
        "[![](https://colab.research.google.com/assets/colab-badge.svg)](https://github.com/DL4DS/fa2026_discussions/blob/main/discussion_04.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "czVEGgv9YwoO"
      },
      "source": [
        "In this discussion notebook, you will practice using PyTorch's frameworks for repeatable data management and reusable model designs.\n",
        "You will also track gradient statistics during the fitting process.\n",
        "\n",
        "When you are done writing code, make sure to run all the cells and then submit your notebook in Gradescope.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Demo 1 - Creating a data loader"
      ],
      "metadata": {
        "id": "dxPDDMaKBnx2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this demo, we will create a data loader for the Iris Flower Dataset, a classic machine learning dataset used for classification. It contains measurements of sepal and petal length and width for three species of iris flowers (setosa, versicolor, virginica). Our goal is to load this data from GitHub, convert it into tensors, and use PyTorch's DataLoader for efficient batching and training."
      ],
      "metadata": {
        "id": "jIl036ZHB-zz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "pGR8SPRjyWd0"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Read the Iris dataset\n",
        "url = \"https://raw.githubusercontent.com/mwaskom/seaborn-data/master/iris.csv\"\n",
        "iris_df = pd.read_csv(url)\n",
        "\n",
        "iris_df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 201
        },
        "id": "4wZ0bwXDB-f_",
        "outputId": "617a3f9e-4cad-40c3-8176-77c2c435f91a"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   sepal_length  sepal_width  petal_length  petal_width species\n",
              "0           5.1          3.5           1.4          0.2  setosa\n",
              "1           4.9          3.0           1.4          0.2  setosa\n",
              "2           4.7          3.2           1.3          0.2  setosa\n",
              "3           4.6          3.1           1.5          0.2  setosa\n",
              "4           5.0          3.6           1.4          0.2  setosa"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6ffbda9e-748e-40f2-9cb5-8008472514e9\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sepal_length</th>\n",
              "      <th>sepal_width</th>\n",
              "      <th>petal_length</th>\n",
              "      <th>petal_width</th>\n",
              "      <th>species</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5.1</td>\n",
              "      <td>3.5</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4.9</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4.7</td>\n",
              "      <td>3.2</td>\n",
              "      <td>1.3</td>\n",
              "      <td>0.2</td>\n",
              "      <td>setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4.6</td>\n",
              "      <td>3.1</td>\n",
              "      <td>1.5</td>\n",
              "      <td>0.2</td>\n",
              "      <td>setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5.0</td>\n",
              "      <td>3.6</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>setosa</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6ffbda9e-748e-40f2-9cb5-8008472514e9')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-6ffbda9e-748e-40f2-9cb5-8008472514e9 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-6ffbda9e-748e-40f2-9cb5-8008472514e9');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "iris_df",
              "summary": "{\n  \"name\": \"iris_df\",\n  \"rows\": 150,\n  \"fields\": [\n    {\n      \"column\": \"sepal_length\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.8280661279778629,\n        \"min\": 4.3,\n        \"max\": 7.9,\n        \"num_unique_values\": 35,\n        \"samples\": [\n          6.2,\n          4.5,\n          5.6\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sepal_width\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.435866284936698,\n        \"min\": 2.0,\n        \"max\": 4.4,\n        \"num_unique_values\": 23,\n        \"samples\": [\n          2.3,\n          4.0,\n          3.5\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"petal_length\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.7652982332594667,\n        \"min\": 1.0,\n        \"max\": 6.9,\n        \"num_unique_values\": 43,\n        \"samples\": [\n          6.7,\n          3.8,\n          3.7\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"petal_width\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.7622376689603465,\n        \"min\": 0.1,\n        \"max\": 2.5,\n        \"num_unique_values\": 22,\n        \"samples\": [\n          0.2,\n          1.2,\n          1.3\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"species\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"setosa\",\n          \"versicolor\",\n          \"virginica\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can create a dataloader for this data set, separating our features and our target. Our target column for this dataset is \"species\"."
      ],
      "metadata": {
        "id": "yFMD6xriCNU_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class IrisDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, dataframe):\n",
        "\n",
        "        # Convert species to classes\n",
        "        self.label_map = {\n",
        "            \"setosa\": 0,\n",
        "            \"versicolor\": 1,\n",
        "            \"virginica\": 2\n",
        "        }\n",
        "\n",
        "        dataframe = dataframe.copy()\n",
        "        dataframe[\"species\"] = dataframe[\"species\"].map(self.label_map)\n",
        "\n",
        "        # Features (remove target column)\n",
        "        self.data = dataframe.drop(columns=[\"species\"]).values.astype(float)\n",
        "\n",
        "        # Targets\n",
        "        self.targets = dataframe[\"species\"].values.astype(int)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "\n",
        "        # Convert to tensors\n",
        "        x = torch.tensor(self.data[idx], dtype=torch.float32)\n",
        "        y = torch.tensor(self.targets[idx], dtype=torch.long)\n",
        "\n",
        "        return x, y"
      ],
      "metadata": {
        "id": "VUgSbZnZCLPX"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, we create a dataset object using our dataframe"
      ],
      "metadata": {
        "id": "VE-sWUUkDDjS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "iris_dataset = IrisDataset(iris_df)\n",
        "\n",
        "iris_dataloader = DataLoader(\n",
        "    iris_dataset,\n",
        "    batch_size=16,\n",
        "    shuffle=True\n",
        ")"
      ],
      "metadata": {
        "id": "rUkrAggjC9l0"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# DO NOT CHANGE\n",
        "\n",
        "for batch_input, batch_output in iris_dataloader:\n",
        "    print(\"INPUT\", batch_input)\n",
        "    print(\"OUTPUT\", batch_output)\n",
        "    break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mckam2TZDJU0",
        "outputId": "5039bed6-6481-4b8b-8abf-8e5ff4003b4d"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INPUT tensor([[5.1000, 3.5000, 1.4000, 0.3000],\n",
            "        [4.7000, 3.2000, 1.3000, 0.2000],\n",
            "        [5.4000, 3.4000, 1.7000, 0.2000],\n",
            "        [5.2000, 4.1000, 1.5000, 0.1000],\n",
            "        [4.9000, 2.5000, 4.5000, 1.7000],\n",
            "        [6.4000, 2.7000, 5.3000, 1.9000],\n",
            "        [6.3000, 2.5000, 5.0000, 1.9000],\n",
            "        [6.3000, 3.3000, 4.7000, 1.6000],\n",
            "        [5.5000, 2.3000, 4.0000, 1.3000],\n",
            "        [5.0000, 3.5000, 1.6000, 0.6000],\n",
            "        [4.4000, 3.2000, 1.3000, 0.2000],\n",
            "        [5.9000, 3.0000, 5.1000, 1.8000],\n",
            "        [5.7000, 2.5000, 5.0000, 2.0000],\n",
            "        [5.8000, 2.7000, 5.1000, 1.9000],\n",
            "        [5.1000, 3.5000, 1.4000, 0.2000],\n",
            "        [4.8000, 3.4000, 1.6000, 0.2000]])\n",
            "OUTPUT tensor([0, 0, 0, 0, 2, 2, 2, 1, 1, 0, 0, 2, 2, 2, 0, 0])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sZSF0GvD0TgV"
      },
      "source": [
        "## Problem 1 - Setup Dataset and DataLoader Objects\n",
        "\n",
        "PyTorch provides various utilities to help managing large data sets.\n",
        "In this problem, you will implement `Dataset` and `DataLoader` objects for the Pima Indians Diabetes data set.\n",
        "This data set is small and easily fits in memory, but these objects will also help with randomization and batching for stochastic gradient descent.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pv-QdpAr20o4"
      },
      "source": [
        "Here is a link to PyTorch's [Datasets & DataLoaders tutorial](https://docs.pytorch.org/tutorials/beginner/basics/data_tutorial.html)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "30JCw4JtyP4T",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 201
        },
        "outputId": "30591e08-2263-424e-8553-846da883a8b3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
              "0            6      148             72             35        0  33.6   \n",
              "1            1       85             66             29        0  26.6   \n",
              "2            8      183             64              0        0  23.3   \n",
              "3            1       89             66             23       94  28.1   \n",
              "4            0      137             40             35      168  43.1   \n",
              "\n",
              "   DiabetesPedigreeFunction  Age  Outcome  \n",
              "0                     0.627   50        1  \n",
              "1                     0.351   31        0  \n",
              "2                     0.672   32        1  \n",
              "3                     0.167   21        0  \n",
              "4                     2.288   33        1  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d2634cd9-f318-4353-8d5d-1a6952b1eb64\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Pregnancies</th>\n",
              "      <th>Glucose</th>\n",
              "      <th>BloodPressure</th>\n",
              "      <th>SkinThickness</th>\n",
              "      <th>Insulin</th>\n",
              "      <th>BMI</th>\n",
              "      <th>DiabetesPedigreeFunction</th>\n",
              "      <th>Age</th>\n",
              "      <th>Outcome</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>6</td>\n",
              "      <td>148</td>\n",
              "      <td>72</td>\n",
              "      <td>35</td>\n",
              "      <td>0</td>\n",
              "      <td>33.6</td>\n",
              "      <td>0.627</td>\n",
              "      <td>50</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>85</td>\n",
              "      <td>66</td>\n",
              "      <td>29</td>\n",
              "      <td>0</td>\n",
              "      <td>26.6</td>\n",
              "      <td>0.351</td>\n",
              "      <td>31</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>8</td>\n",
              "      <td>183</td>\n",
              "      <td>64</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>23.3</td>\n",
              "      <td>0.672</td>\n",
              "      <td>32</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>89</td>\n",
              "      <td>66</td>\n",
              "      <td>23</td>\n",
              "      <td>94</td>\n",
              "      <td>28.1</td>\n",
              "      <td>0.167</td>\n",
              "      <td>21</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>137</td>\n",
              "      <td>40</td>\n",
              "      <td>35</td>\n",
              "      <td>168</td>\n",
              "      <td>43.1</td>\n",
              "      <td>2.288</td>\n",
              "      <td>33</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d2634cd9-f318-4353-8d5d-1a6952b1eb64')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-d2634cd9-f318-4353-8d5d-1a6952b1eb64 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-d2634cd9-f318-4353-8d5d-1a6952b1eb64');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 768,\n  \"fields\": [\n    {\n      \"column\": \"Pregnancies\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3,\n        \"min\": 0,\n        \"max\": 17,\n        \"num_unique_values\": 17,\n        \"samples\": [\n          6,\n          1,\n          3\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Glucose\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 31,\n        \"min\": 0,\n        \"max\": 199,\n        \"num_unique_values\": 136,\n        \"samples\": [\n          151,\n          101,\n          112\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"BloodPressure\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 19,\n        \"min\": 0,\n        \"max\": 122,\n        \"num_unique_values\": 47,\n        \"samples\": [\n          86,\n          46,\n          85\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"SkinThickness\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 15,\n        \"min\": 0,\n        \"max\": 99,\n        \"num_unique_values\": 51,\n        \"samples\": [\n          7,\n          12,\n          48\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Insulin\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 115,\n        \"min\": 0,\n        \"max\": 846,\n        \"num_unique_values\": 186,\n        \"samples\": [\n          52,\n          41,\n          183\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"BMI\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 7.8841603203754405,\n        \"min\": 0.0,\n        \"max\": 67.1,\n        \"num_unique_values\": 248,\n        \"samples\": [\n          19.9,\n          31.0,\n          38.1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"DiabetesPedigreeFunction\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.33132859501277484,\n        \"min\": 0.078,\n        \"max\": 2.42,\n        \"num_unique_values\": 517,\n        \"samples\": [\n          1.731,\n          0.426,\n          0.138\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Age\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 11,\n        \"min\": 21,\n        \"max\": 81,\n        \"num_unique_values\": 52,\n        \"samples\": [\n          60,\n          47,\n          72\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Outcome\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "df = pd.read_csv(\"https://github.com/npradaschnor/Pima-Indians-Diabetes-Dataset/raw/refs/heads/master/diabetes.csv\")\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "Sv_wHdCd1mci",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1b57ebf7-3f4e-45eb-fde1-22e27e916227"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "768"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "len(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-SjxA1G91uA3"
      },
      "source": [
        "Finish the implementation of the `DiabetesDataset` class below by implementing the missing methods for `torch.utils.data.Dataset`.\n",
        "The dataset should return pairs of tensors where the first tensor is the input row and the second tensor has the corresponding `Outcome` target."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "YYy3PRRn1M-O"
      },
      "outputs": [],
      "source": [
        "# TODO: Create init function with \"Outcome\" as the target\n",
        "# Return the length of the data in the __len__ function\n",
        "# Convert data and targets to tensors by creating a __getitem__ function\n",
        "\n",
        "class DiabetesDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, dataframe):\n",
        "        self.data = dataframe.drop(columns=[\"Outcome\"]).values.astype(float) # Specify our features\n",
        "        self.target = dataframe[\"Outcome\"].values.astype(int) # Specify our target\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # Convert features and target to tensors\n",
        "        x = torch.tensor(self.data[idx], dtype=torch.float32)\n",
        "        y = torch.tensor(self.target[idx], dtype=torch.long)\n",
        "        return x, y"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wAsEy7MS1UNK"
      },
      "source": [
        "Create a DataLoader object using an instance of your `DiabetesDataset` class and configure it to randomize the data and return batches of 100 rows at a time."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "KI98yVUU1SvG"
      },
      "outputs": [],
      "source": [
        "# YOUR CHANGES HERE\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "dataset = DiabetesDataset(df) # Hint: Use our dataframe to create the dataset object\n",
        "\n",
        "dataloader = DataLoader(\n",
        "    dataset,\n",
        "    batch_size=100,\n",
        "    shuffle=True\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t1MVuFm_4RYD"
      },
      "source": [
        "Test your data loader."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "jsSrmBVk4Ang",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "06885a2c-c454-4aab-a02a-fbf66668968f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INPUT tensor([[8.0000e+00, 1.9400e+02, 8.0000e+01, 0.0000e+00, 0.0000e+00, 2.6100e+01,\n",
            "         5.5100e-01, 6.7000e+01],\n",
            "        [3.0000e+00, 7.8000e+01, 5.0000e+01, 3.2000e+01, 8.8000e+01, 3.1000e+01,\n",
            "         2.4800e-01, 2.6000e+01],\n",
            "        [1.0000e+00, 1.2400e+02, 6.0000e+01, 3.2000e+01, 0.0000e+00, 3.5800e+01,\n",
            "         5.1400e-01, 2.1000e+01],\n",
            "        [1.0000e+00, 1.1600e+02, 7.8000e+01, 2.9000e+01, 1.8000e+02, 3.6100e+01,\n",
            "         4.9600e-01, 2.5000e+01],\n",
            "        [2.0000e+00, 6.8000e+01, 7.0000e+01, 3.2000e+01, 6.6000e+01, 2.5000e+01,\n",
            "         1.8700e-01, 2.5000e+01],\n",
            "        [4.0000e+00, 1.9700e+02, 7.0000e+01, 3.9000e+01, 7.4400e+02, 3.6700e+01,\n",
            "         2.3290e+00, 3.1000e+01],\n",
            "        [9.0000e+00, 1.0200e+02, 7.6000e+01, 3.7000e+01, 0.0000e+00, 3.2900e+01,\n",
            "         6.6500e-01, 4.6000e+01],\n",
            "        [6.0000e+00, 8.7000e+01, 8.0000e+01, 0.0000e+00, 0.0000e+00, 2.3200e+01,\n",
            "         8.4000e-02, 3.2000e+01],\n",
            "        [1.2000e+01, 1.0000e+02, 8.4000e+01, 3.3000e+01, 1.0500e+02, 3.0000e+01,\n",
            "         4.8800e-01, 4.6000e+01],\n",
            "        [2.0000e+00, 9.2000e+01, 5.2000e+01, 0.0000e+00, 0.0000e+00, 3.0100e+01,\n",
            "         1.4100e-01, 2.2000e+01],\n",
            "        [0.0000e+00, 1.4100e+02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.2400e+01,\n",
            "         2.0500e-01, 2.9000e+01],\n",
            "        [4.0000e+00, 1.2700e+02, 8.8000e+01, 1.1000e+01, 1.5500e+02, 3.4500e+01,\n",
            "         5.9800e-01, 2.8000e+01],\n",
            "        [2.0000e+00, 1.2300e+02, 4.8000e+01, 3.2000e+01, 1.6500e+02, 4.2100e+01,\n",
            "         5.2000e-01, 2.6000e+01],\n",
            "        [9.0000e+00, 9.1000e+01, 6.8000e+01, 0.0000e+00, 0.0000e+00, 2.4200e+01,\n",
            "         2.0000e-01, 5.8000e+01],\n",
            "        [4.0000e+00, 9.1000e+01, 7.0000e+01, 3.2000e+01, 8.8000e+01, 3.3100e+01,\n",
            "         4.4600e-01, 2.2000e+01],\n",
            "        [1.4000e+01, 1.0000e+02, 7.8000e+01, 2.5000e+01, 1.8400e+02, 3.6600e+01,\n",
            "         4.1200e-01, 4.6000e+01],\n",
            "        [9.0000e+00, 1.6500e+02, 8.8000e+01, 0.0000e+00, 0.0000e+00, 3.0400e+01,\n",
            "         3.0200e-01, 4.9000e+01],\n",
            "        [6.0000e+00, 1.5400e+02, 7.8000e+01, 4.1000e+01, 1.4000e+02, 4.6100e+01,\n",
            "         5.7100e-01, 2.7000e+01],\n",
            "        [1.0000e+01, 9.2000e+01, 6.2000e+01, 0.0000e+00, 0.0000e+00, 2.5900e+01,\n",
            "         1.6700e-01, 3.1000e+01],\n",
            "        [6.0000e+00, 1.5400e+02, 7.4000e+01, 3.2000e+01, 1.9300e+02, 2.9300e+01,\n",
            "         8.3900e-01, 3.9000e+01],\n",
            "        [6.0000e+00, 1.1500e+02, 6.0000e+01, 3.9000e+01, 0.0000e+00, 3.3700e+01,\n",
            "         2.4500e-01, 4.0000e+01],\n",
            "        [2.0000e+00, 8.7000e+01, 5.8000e+01, 1.6000e+01, 5.2000e+01, 3.2700e+01,\n",
            "         1.6600e-01, 2.5000e+01],\n",
            "        [1.0000e+00, 1.0700e+02, 5.0000e+01, 1.9000e+01, 0.0000e+00, 2.8300e+01,\n",
            "         1.8100e-01, 2.9000e+01],\n",
            "        [1.1000e+01, 1.2700e+02, 1.0600e+02, 0.0000e+00, 0.0000e+00, 3.9000e+01,\n",
            "         1.9000e-01, 5.1000e+01],\n",
            "        [1.0000e+00, 1.4300e+02, 8.4000e+01, 2.3000e+01, 3.1000e+02, 4.2400e+01,\n",
            "         1.0760e+00, 2.2000e+01],\n",
            "        [4.0000e+00, 1.4600e+02, 7.8000e+01, 0.0000e+00, 0.0000e+00, 3.8500e+01,\n",
            "         5.2000e-01, 6.7000e+01],\n",
            "        [1.3000e+01, 1.0600e+02, 7.0000e+01, 0.0000e+00, 0.0000e+00, 3.4200e+01,\n",
            "         2.5100e-01, 5.2000e+01],\n",
            "        [1.3000e+01, 1.0600e+02, 7.2000e+01, 5.4000e+01, 0.0000e+00, 3.6600e+01,\n",
            "         1.7800e-01, 4.5000e+01],\n",
            "        [1.1000e+01, 1.2000e+02, 8.0000e+01, 3.7000e+01, 1.5000e+02, 4.2300e+01,\n",
            "         7.8500e-01, 4.8000e+01],\n",
            "        [9.0000e+00, 7.2000e+01, 7.8000e+01, 2.5000e+01, 0.0000e+00, 3.1600e+01,\n",
            "         2.8000e-01, 3.8000e+01],\n",
            "        [7.0000e+00, 1.9600e+02, 9.0000e+01, 0.0000e+00, 0.0000e+00, 3.9800e+01,\n",
            "         4.5100e-01, 4.1000e+01],\n",
            "        [6.0000e+00, 1.1400e+02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
            "         1.8900e-01, 2.6000e+01],\n",
            "        [7.0000e+00, 1.1900e+02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.5200e+01,\n",
            "         2.0900e-01, 3.7000e+01],\n",
            "        [0.0000e+00, 1.2800e+02, 6.8000e+01, 1.9000e+01, 1.8000e+02, 3.0500e+01,\n",
            "         1.3910e+00, 2.5000e+01],\n",
            "        [1.0000e+00, 1.3000e+02, 6.0000e+01, 2.3000e+01, 1.7000e+02, 2.8600e+01,\n",
            "         6.9200e-01, 2.1000e+01],\n",
            "        [0.0000e+00, 8.6000e+01, 6.8000e+01, 3.2000e+01, 0.0000e+00, 3.5800e+01,\n",
            "         2.3800e-01, 2.5000e+01],\n",
            "        [1.0000e+00, 1.1800e+02, 5.8000e+01, 3.6000e+01, 9.4000e+01, 3.3300e+01,\n",
            "         2.6100e-01, 2.3000e+01],\n",
            "        [2.0000e+00, 1.0800e+02, 5.2000e+01, 2.6000e+01, 6.3000e+01, 3.2500e+01,\n",
            "         3.1800e-01, 2.2000e+01],\n",
            "        [8.0000e+00, 1.9700e+02, 7.4000e+01, 0.0000e+00, 0.0000e+00, 2.5900e+01,\n",
            "         1.1910e+00, 3.9000e+01],\n",
            "        [1.0000e+00, 8.3000e+01, 6.8000e+01, 0.0000e+00, 0.0000e+00, 1.8200e+01,\n",
            "         6.2400e-01, 2.7000e+01],\n",
            "        [4.0000e+00, 9.0000e+01, 8.8000e+01, 4.7000e+01, 5.4000e+01, 3.7700e+01,\n",
            "         3.6200e-01, 2.9000e+01],\n",
            "        [3.0000e+00, 1.6900e+02, 7.4000e+01, 1.9000e+01, 1.2500e+02, 2.9900e+01,\n",
            "         2.6800e-01, 3.1000e+01],\n",
            "        [5.0000e+00, 1.1600e+02, 7.4000e+01, 2.9000e+01, 0.0000e+00, 3.2300e+01,\n",
            "         6.6000e-01, 3.5000e+01],\n",
            "        [1.0000e+01, 1.1100e+02, 7.0000e+01, 2.7000e+01, 0.0000e+00, 2.7500e+01,\n",
            "         1.4100e-01, 4.0000e+01],\n",
            "        [3.0000e+00, 1.1300e+02, 4.4000e+01, 1.3000e+01, 0.0000e+00, 2.2400e+01,\n",
            "         1.4000e-01, 2.2000e+01],\n",
            "        [0.0000e+00, 1.0500e+02, 6.4000e+01, 4.1000e+01, 1.4200e+02, 4.1500e+01,\n",
            "         1.7300e-01, 2.2000e+01],\n",
            "        [0.0000e+00, 7.4000e+01, 5.2000e+01, 1.0000e+01, 3.6000e+01, 2.7800e+01,\n",
            "         2.6900e-01, 2.2000e+01],\n",
            "        [1.0000e+00, 1.2600e+02, 5.6000e+01, 2.9000e+01, 1.5200e+02, 2.8700e+01,\n",
            "         8.0100e-01, 2.1000e+01],\n",
            "        [3.0000e+00, 1.2800e+02, 7.2000e+01, 2.5000e+01, 1.9000e+02, 3.2400e+01,\n",
            "         5.4900e-01, 2.7000e+01],\n",
            "        [8.0000e+00, 1.3300e+02, 7.2000e+01, 0.0000e+00, 0.0000e+00, 3.2900e+01,\n",
            "         2.7000e-01, 3.9000e+01],\n",
            "        [2.0000e+00, 1.9700e+02, 7.0000e+01, 9.9000e+01, 0.0000e+00, 3.4700e+01,\n",
            "         5.7500e-01, 6.2000e+01],\n",
            "        [1.0000e+00, 9.9000e+01, 5.8000e+01, 1.0000e+01, 0.0000e+00, 2.5400e+01,\n",
            "         5.5100e-01, 2.1000e+01],\n",
            "        [5.0000e+00, 1.1500e+02, 7.6000e+01, 0.0000e+00, 0.0000e+00, 3.1200e+01,\n",
            "         3.4300e-01, 4.4000e+01],\n",
            "        [2.0000e+00, 9.0000e+01, 8.0000e+01, 1.4000e+01, 5.5000e+01, 2.4400e+01,\n",
            "         2.4900e-01, 2.4000e+01],\n",
            "        [5.0000e+00, 1.3900e+02, 8.0000e+01, 3.5000e+01, 1.6000e+02, 3.1600e+01,\n",
            "         3.6100e-01, 2.5000e+01],\n",
            "        [2.0000e+00, 1.0700e+02, 7.4000e+01, 3.0000e+01, 1.0000e+02, 3.3600e+01,\n",
            "         4.0400e-01, 2.3000e+01],\n",
            "        [1.7000e+01, 1.6300e+02, 7.2000e+01, 4.1000e+01, 1.1400e+02, 4.0900e+01,\n",
            "         8.1700e-01, 4.7000e+01],\n",
            "        [6.0000e+00, 1.6500e+02, 6.8000e+01, 2.6000e+01, 1.6800e+02, 3.3600e+01,\n",
            "         6.3100e-01, 4.9000e+01],\n",
            "        [6.0000e+00, 1.3400e+02, 7.0000e+01, 2.3000e+01, 1.3000e+02, 3.5400e+01,\n",
            "         5.4200e-01, 2.9000e+01],\n",
            "        [1.0000e+00, 1.0000e+02, 7.2000e+01, 1.2000e+01, 7.0000e+01, 2.5300e+01,\n",
            "         6.5800e-01, 2.8000e+01],\n",
            "        [0.0000e+00, 1.3700e+02, 4.0000e+01, 3.5000e+01, 1.6800e+02, 4.3100e+01,\n",
            "         2.2880e+00, 3.3000e+01],\n",
            "        [6.0000e+00, 9.2000e+01, 6.2000e+01, 3.2000e+01, 1.2600e+02, 3.2000e+01,\n",
            "         8.5000e-02, 4.6000e+01],\n",
            "        [0.0000e+00, 1.0000e+02, 7.0000e+01, 2.6000e+01, 5.0000e+01, 3.0800e+01,\n",
            "         5.9700e-01, 2.1000e+01],\n",
            "        [6.0000e+00, 9.3000e+01, 5.0000e+01, 3.0000e+01, 6.4000e+01, 2.8700e+01,\n",
            "         3.5600e-01, 2.3000e+01],\n",
            "        [7.0000e+00, 1.1400e+02, 6.6000e+01, 0.0000e+00, 0.0000e+00, 3.2800e+01,\n",
            "         2.5800e-01, 4.2000e+01],\n",
            "        [1.1000e+01, 1.3800e+02, 7.4000e+01, 2.6000e+01, 1.4400e+02, 3.6100e+01,\n",
            "         5.5700e-01, 5.0000e+01],\n",
            "        [5.0000e+00, 1.2800e+02, 8.0000e+01, 0.0000e+00, 0.0000e+00, 3.4600e+01,\n",
            "         1.4400e-01, 4.5000e+01],\n",
            "        [1.0000e+00, 7.7000e+01, 5.6000e+01, 3.0000e+01, 5.6000e+01, 3.3300e+01,\n",
            "         1.2510e+00, 2.4000e+01],\n",
            "        [4.0000e+00, 1.1400e+02, 6.5000e+01, 0.0000e+00, 0.0000e+00, 2.1900e+01,\n",
            "         4.3200e-01, 3.7000e+01],\n",
            "        [7.0000e+00, 1.3600e+02, 9.0000e+01, 0.0000e+00, 0.0000e+00, 2.9900e+01,\n",
            "         2.1000e-01, 5.0000e+01],\n",
            "        [1.0000e+00, 0.0000e+00, 7.4000e+01, 2.0000e+01, 2.3000e+01, 2.7700e+01,\n",
            "         2.9900e-01, 2.1000e+01],\n",
            "        [1.0000e+00, 1.1900e+02, 8.6000e+01, 3.9000e+01, 2.2000e+02, 4.5600e+01,\n",
            "         8.0800e-01, 2.9000e+01],\n",
            "        [4.0000e+00, 9.4000e+01, 6.5000e+01, 2.2000e+01, 0.0000e+00, 2.4700e+01,\n",
            "         1.4800e-01, 2.1000e+01],\n",
            "        [3.0000e+00, 9.6000e+01, 7.8000e+01, 3.9000e+01, 0.0000e+00, 3.7300e+01,\n",
            "         2.3800e-01, 4.0000e+01],\n",
            "        [1.0000e+00, 8.1000e+01, 7.4000e+01, 4.1000e+01, 5.7000e+01, 4.6300e+01,\n",
            "         1.0960e+00, 3.2000e+01],\n",
            "        [1.0000e+01, 1.2900e+02, 7.6000e+01, 2.8000e+01, 1.2200e+02, 3.5900e+01,\n",
            "         2.8000e-01, 3.9000e+01],\n",
            "        [0.0000e+00, 1.1900e+02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.2400e+01,\n",
            "         1.4100e-01, 2.4000e+01],\n",
            "        [7.0000e+00, 1.1400e+02, 7.6000e+01, 1.7000e+01, 1.1000e+02, 2.3800e+01,\n",
            "         4.6600e-01, 3.1000e+01],\n",
            "        [5.0000e+00, 1.5500e+02, 8.4000e+01, 4.4000e+01, 5.4500e+02, 3.8700e+01,\n",
            "         6.1900e-01, 3.4000e+01],\n",
            "        [1.0000e+00, 9.1000e+01, 5.4000e+01, 2.5000e+01, 1.0000e+02, 2.5200e+01,\n",
            "         2.3400e-01, 2.3000e+01],\n",
            "        [4.0000e+00, 1.1800e+02, 7.0000e+01, 0.0000e+00, 0.0000e+00, 4.4500e+01,\n",
            "         9.0400e-01, 2.6000e+01],\n",
            "        [4.0000e+00, 1.7100e+02, 7.2000e+01, 0.0000e+00, 0.0000e+00, 4.3600e+01,\n",
            "         4.7900e-01, 2.6000e+01],\n",
            "        [6.0000e+00, 1.2900e+02, 9.0000e+01, 7.0000e+00, 3.2600e+02, 1.9600e+01,\n",
            "         5.8200e-01, 6.0000e+01],\n",
            "        [2.0000e+00, 7.1000e+01, 7.0000e+01, 2.7000e+01, 0.0000e+00, 2.8000e+01,\n",
            "         5.8600e-01, 2.2000e+01],\n",
            "        [8.0000e+00, 6.5000e+01, 7.2000e+01, 2.3000e+01, 0.0000e+00, 3.2000e+01,\n",
            "         6.0000e-01, 4.2000e+01],\n",
            "        [2.0000e+00, 1.5500e+02, 5.2000e+01, 2.7000e+01, 5.4000e+02, 3.8700e+01,\n",
            "         2.4000e-01, 2.5000e+01],\n",
            "        [3.0000e+00, 1.1500e+02, 6.6000e+01, 3.9000e+01, 1.4000e+02, 3.8100e+01,\n",
            "         1.5000e-01, 2.8000e+01],\n",
            "        [3.0000e+00, 1.2500e+02, 5.8000e+01, 0.0000e+00, 0.0000e+00, 3.1600e+01,\n",
            "         1.5100e-01, 2.4000e+01],\n",
            "        [9.0000e+00, 1.7000e+02, 7.4000e+01, 3.1000e+01, 0.0000e+00, 4.4000e+01,\n",
            "         4.0300e-01, 4.3000e+01],\n",
            "        [2.0000e+00, 1.2900e+02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.8500e+01,\n",
            "         3.0400e-01, 4.1000e+01],\n",
            "        [3.0000e+00, 1.4800e+02, 6.6000e+01, 2.5000e+01, 0.0000e+00, 3.2500e+01,\n",
            "         2.5600e-01, 2.2000e+01],\n",
            "        [1.0000e+00, 1.5700e+02, 7.2000e+01, 2.1000e+01, 1.6800e+02, 2.5600e+01,\n",
            "         1.2300e-01, 2.4000e+01],\n",
            "        [0.0000e+00, 8.4000e+01, 8.2000e+01, 3.1000e+01, 1.2500e+02, 3.8200e+01,\n",
            "         2.3300e-01, 2.3000e+01],\n",
            "        [2.0000e+00, 9.1000e+01, 6.2000e+01, 0.0000e+00, 0.0000e+00, 2.7300e+01,\n",
            "         5.2500e-01, 2.2000e+01],\n",
            "        [1.0000e+00, 8.7000e+01, 7.8000e+01, 2.7000e+01, 3.2000e+01, 3.4600e+01,\n",
            "         1.0100e-01, 2.2000e+01],\n",
            "        [1.0000e+00, 1.0900e+02, 6.0000e+01, 8.0000e+00, 1.8200e+02, 2.5400e+01,\n",
            "         9.4700e-01, 2.1000e+01],\n",
            "        [4.0000e+00, 1.0300e+02, 6.0000e+01, 3.3000e+01, 1.9200e+02, 2.4000e+01,\n",
            "         9.6600e-01, 3.3000e+01],\n",
            "        [1.0000e+00, 1.7200e+02, 6.8000e+01, 4.9000e+01, 5.7900e+02, 4.2400e+01,\n",
            "         7.0200e-01, 2.8000e+01],\n",
            "        [8.0000e+00, 1.5500e+02, 6.2000e+01, 2.6000e+01, 4.9500e+02, 3.4000e+01,\n",
            "         5.4300e-01, 4.6000e+01],\n",
            "        [3.0000e+00, 8.4000e+01, 7.2000e+01, 3.2000e+01, 0.0000e+00, 3.7200e+01,\n",
            "         2.6700e-01, 2.8000e+01]])\n",
            "OUTPUT tensor([0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0,\n",
            "        0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0,\n",
            "        1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1,\n",
            "        0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 1, 1, 0])\n"
          ]
        }
      ],
      "source": [
        "# DO NOT CHANGE\n",
        "\n",
        "for batch_input, batch_output in dataloader:\n",
        "    print(\"INPUT\", batch_input)\n",
        "    print(\"OUTPUT\", batch_output)\n",
        "    break"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Demo 2 - Using the Adam Optimizer"
      ],
      "metadata": {
        "id": "hAXdmHzxDYg8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The **Adam** optimizer is an adaptive optimization method that adjusts learning rates for each parameter using past gradients and momentum, making training faster and more stable than standard gradient descent.\n",
        "\n",
        "In this use case, Adam updates the weight matrix and bias using gradients from CrossEntropyLoss, helping the model learn good class boundaries.\n",
        "\n",
        "On the Iris dataset, Adam is used to train a linear model with four input features and three output classes, efficiently learning to separate the three flower species."
      ],
      "metadata": {
        "id": "FYYA-tO5D1s4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class MulticlassLogisticRegression(nn.Module):\n",
        "    def __init__(self, num_features, num_classes):\n",
        "        super().__init__()\n",
        "\n",
        "        # Weights: (features  classes)\n",
        "        self.weights = nn.Parameter(\n",
        "            torch.zeros(num_features, num_classes)\n",
        "        )\n",
        "\n",
        "        # Bias: (classes,)\n",
        "        self.bias = nn.Parameter(\n",
        "            torch.zeros(num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Linear scores (logits)\n",
        "        logits = x @ self.weights + self.bias\n",
        "\n",
        "        # Softmax for multiclass probabilities\n",
        "        return torch.softmax(logits, dim=1)\n"
      ],
      "metadata": {
        "id": "xgqPt5THEc6B"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = MulticlassLogisticRegression(num_features = 4, num_classes = 3)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
        "num_epochs = 1000\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    epoch_loss = 0.0\n",
        "    num_batches = 0\n",
        "\n",
        "    for batch_inputs, batch_targets in iris_dataloader:\n",
        "        batch_targets = batch_targets.long()\n",
        "\n",
        "        outputs = model(batch_inputs)\n",
        "        loss = torch.nn.CrossEntropyLoss()(outputs, batch_targets)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        epoch_loss += loss.item()\n",
        "        num_batches += 1\n",
        "\n",
        "    avg_loss = epoch_loss / num_batches\n",
        "    if epoch % 100 == 0:\n",
        "      print(f\"Epoch {epoch}/{num_epochs}, Average Loss: {avg_loss:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nDzMMG6jDe-e",
        "outputId": "39217790-82db-4908-a635-de800c967751"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0/1000, Average Loss: 1.0794\n",
            "Epoch 100/1000, Average Loss: 0.6444\n",
            "Epoch 200/1000, Average Loss: 0.6075\n",
            "Epoch 300/1000, Average Loss: 0.6030\n",
            "Epoch 400/1000, Average Loss: 0.5884\n",
            "Epoch 500/1000, Average Loss: 0.5846\n",
            "Epoch 600/1000, Average Loss: 0.5829\n",
            "Epoch 700/1000, Average Loss: 0.5805\n",
            "Epoch 800/1000, Average Loss: 0.5821\n",
            "Epoch 900/1000, Average Loss: 0.5778\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uQN5oa87uUcM"
      },
      "source": [
        "## Problem 2 - Use Adam to Optimize Logistic Regression\n",
        "\n",
        "Write a training loop using PyTorch's [`torch.optim.Adam`](https://docs.pytorch.org/docs/stable/generated/torch.optim.Adam.html) to optimize logistic regression.\n",
        "Use the following `LogisticRegression` class for the implementation of logistic regression and [`torch.nn.functional.binary_cross_entropy`](https://docs.pytorch.org/docs/stable/generated/torch.nn.functional.binary_cross_entropy.html) for the loss function.\n",
        "\n",
        "Run the training loop for 10 epochs printing the average training batch loss for each epoch."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "lsWgbTdryuZn"
      },
      "outputs": [],
      "source": [
        "class LogisticRegression(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        # use torch.nn.Parameter to register these as model parameters\n",
        "        self.weights = torch.nn.Parameter(torch.zeros(len(df.columns)-1, 1))\n",
        "        self.bias = torch.nn.Parameter(torch.zeros(1))\n",
        "\n",
        "    def forward(self, x):\n",
        "        return torch.sigmoid(x @ self.weights + self.bias)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "fybVGPI6Cul5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "052eed36-d890-4c1c-a8aa-bbe4513ccaf9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10, Average Loss: 0.8815\n",
            "Epoch 2/10, Average Loss: 0.6864\n",
            "Epoch 3/10, Average Loss: 0.6515\n",
            "Epoch 4/10, Average Loss: 0.7085\n",
            "Epoch 5/10, Average Loss: 0.7442\n",
            "Epoch 6/10, Average Loss: 0.6772\n",
            "Epoch 7/10, Average Loss: 0.6949\n",
            "Epoch 8/10, Average Loss: 0.7016\n",
            "Epoch 9/10, Average Loss: 0.6326\n",
            "Epoch 10/10, Average Loss: 0.6327\n"
          ]
        }
      ],
      "source": [
        "# YOUR CHANGES HERE\n",
        "\n",
        "import torch.nn.functional as F\n",
        "\n",
        "model = LogisticRegression()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
        "num_epochs = 10\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    epoch_loss = 0.0\n",
        "    num_batches = 0\n",
        "\n",
        "    for batch_inputs, batch_targets in dataloader:\n",
        "        batch_targets = batch_targets.view(-1, 1).float() # Cast to float\n",
        "\n",
        "\n",
        "        outputs = model(batch_inputs)\n",
        "        loss = torch.nn.functional.binary_cross_entropy(outputs, batch_targets)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        epoch_loss += loss.item()\n",
        "        num_batches += 1\n",
        "\n",
        "    avg_loss = epoch_loss / num_batches\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs}, Average Loss: {avg_loss:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q9u8dbehE6TS"
      },
      "source": [
        "## Problem 3 - Track Training Statistics and Gradients\n",
        "\n",
        "Copy your training loop from problem 2 and modify it as follows.\n",
        "\n",
        "1. Increase the number of epochs to 100.\n",
        "2. Track the training loss of each batch.\n",
        "3. Track the training accuracy of each batch.\n",
        "4. Track the loss gradient of each batch for both the weights and bias of the logistic regression.\n",
        "5. After the training loop is done, plot the data from 2-4. Use Matplotlib's subplot function to stack the charts vertically so they are aligned."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YVPeZnG-GSTr"
      },
      "outputs": [],
      "source": [
        "# YOUR CHANGES HERE\n",
        "\n",
        "# TODO: Define model and optimizer\n",
        "\n",
        "model = __FILL__\n",
        "optimizer = __FILL__\n",
        "\n",
        "# TODO: Initialize lists for tracking losses, accuracies, weights, and biases\n",
        "__FILL__ = []\n",
        "__FILL__ = []\n",
        "__FILL__ = []\n",
        "__FILL__ = []\n",
        "\n",
        "# TODO: Run training loop\n",
        "\n",
        "for epoch in range(__FILL__):\n",
        "    for __FILL__, __FILL__ in __FILL__:\n",
        "        batch_targets = batch_targets.view(-1, 1)\n",
        "\n",
        "        outputs = __FILL__\n",
        "        loss = __FILL__\n",
        "\n",
        "        optimizer.__FILL__\n",
        "        loss.__FILL__\n",
        "\n",
        "        __FILL__.append(loss.item()) # Loss list\n",
        "        preds = (outputs >= 0.5).float()\n",
        "        __FILL__.append((preds == batch_targets).float().mean().item()) # Accuracy list\n",
        "        __FILL__.append(model.weights.grad.detach().numpy().copy()) # Weights list\n",
        "        __FILL__.append(model.bias.grad.detach().numpy().copy()) # Bias list\n",
        "\n",
        "        optimizer.__FILL__\n",
        "\n",
        "__FILL__ = np.array(__FILL__)  # Convert gradient weights to numpy\n",
        "__FILL__ = np.array(__FILL__).flatten() # Convert biases weights to numpy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OB38bpH5GdPV"
      },
      "outputs": [],
      "source": [
        "# YOUR CHANGES HERE\n",
        "\n",
        "plt.figure(figsize=(10, 12))\n",
        "\n",
        "# 1. Training Loss\n",
        "plt.subplot(3, 1, 1)\n",
        "plt.plot(__FILL__, color='blue') # Loss array\n",
        "plt.title(\"Training Loss per Batch\")\n",
        "plt.xlabel(\"Batch\")\n",
        "plt.ylabel(__FILL__) # Label\n",
        "plt.grid(True)\n",
        "\n",
        "# 2. Training Accuracy\n",
        "plt.subplot(3, 1, 2)\n",
        "plt.plot(__FILL__, color='orange') # Accuracy array\n",
        "plt.title(\"Training Accuracy per Batch\")\n",
        "plt.xlabel(\"Batch\")\n",
        "plt.ylabel(__FILL__) # Label\n",
        "plt.grid(True)\n",
        "\n",
        "# 3. Gradients\n",
        "plt.subplot(3, 1, 3)\n",
        "plt.plot(__FILL__, label=\"bias\", color='red') # Bias array\n",
        "for i in range(__FILL__.shape[1]): # Weight array\n",
        "    plt.plot(__FILL__[:, i], label=f\"{df.columns[i]}\") # Weight array\n",
        "plt.title(\"Gradients per Batch\")\n",
        "plt.xlabel(\"Batch\")\n",
        "plt.ylabel(__FILL__) # Label\n",
        "plt.legend(fontsize=8)\n",
        "plt.grid(True)\n",
        "\n",
        "plt.subplots_adjust(hspace=0.8)\n",
        "plt.show()\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}